{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf5c27-7afe-4810-bd04-35afd59b70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Importing necessary libraries.\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.src.utils import np_utils\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "df = pd.read_csv("/kaggle/input/fer2013/fer2013.csv")
    "# for simplicity, add the dataset in the same folder as your main.py and write:\n",
    "# df = pd.read_csv(\"fer2013.csv\")\n",
    "# print(df.info())\n",
    "\n",
    "X_train, train_y, X_test, test_y = [], [], [], []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val = row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "            X_train.append(np.array(val, 'float32'))\n",
    "            train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "            X_test.append(np.array(val, 'float32'))\n",
    "            test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"Error occurred at index : {index} and row {row}\")\n",
    "\n",
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "width, height = 48, 48\n",
    "\n",
    "# print(f\"X_train sample data : {X_train[0:3]}\")\n",
    "# print(f\"train_y sample data : {train_y[0:3]}\")\n",
    "# print(f\"X_test sample data : {X_test[0:3]}\")\n",
    "# print(f\"test_y sample data : {test_y[0:3]}\")\n",
    "\n",
    "X_train = np.array(X_train, 'float32')\n",
    "train_y = np.array(train_y, 'float32')\n",
    "X_test = np.array(X_test, 'float32')\n",
    "test_y = np.array(test_y, 'float32')\n",
    "\n",
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
    "\n",
    "# Normalising the Data between 0 and 1\n",
    "# We'll calculate the mean of the data and divide it by the std deviation\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "# print(f\"X_train sample data : {X_train[0:3]}\")\n",
    "# print(f\"train_y sample data : {train_y[0:3]}\")\n",
    "# print(f\"X_test sample data : {X_test[0:3]}\")\n",
    "# print(f\"test_y sample data : {test_y[0:3]}\")\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], width, height, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], width, height, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 2nd Convolution Layer\n",
    "model.add(Conv2D(num_features, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(num_features, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 3rd Convolution Layer\n",
    "model.add(Conv2D(num_features*2, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(num_features*2, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding dense layer\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(X_train, train_y, batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)\n",
    "\n",
    "# Saving Model\n",
    "fer_json = model.to_json()\n",
    "with open(\"model_fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"model_fer.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
